{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = [\"a.csv\" , \"b.csv\" , \"c.csv\" , \"e.csv\" ]\n",
    "columns_to_drop_bi = ['proto', 'ip_src', 'ip_dst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Federated Learner:\n",
    "\n",
    "Parameters:\n",
    "\n",
    "x: The data to be decided (array)\n",
    "\n",
    "clfs:  The binary classifiers;(List of Classifiers)\n",
    "\n",
    "p_nodes: The proportion of the nodes;(List)\n",
    "\n",
    "gms: Gassian Mixture Models (List of GMMs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x, clfs, p_nodes, gms):\n",
    "    p_x_node = np.zeros((len(x), len(clfs))) \n",
    "    p_y_given_node = np.zeros((len(x), len(clfs))) \n",
    "    for i in range(len(clfs)):\n",
    "        p_x_node[:, i] = p_nodes[i] * np.exp(gms[i].score_samples(x))\n",
    "        p_y_given_node[:, i] = clfs[i].predict_proba(x)[:, 1]\n",
    "    \n",
    "    p_y = p_y_given_node * p_x_node / (np.sum(p_x_node, axis=-1, keepdims=True) + 1e-10)\n",
    "\n",
    "    p_y = np.hstack([1-np.sum(p_y, axis=-1, keepdims=True), p_y])\n",
    "\n",
    "    return np.argmax(p_y, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary=RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def Fed_RF_learn(input_file, columns_to_drop_bi, random_state,  K, test_size = 0.25):\n",
    "\n",
    "    data_list = []\n",
    "    for i in range(len(input_file)):\n",
    "        data = pd.read_csv(input_file[i])\n",
    "        data.drop(columns = columns_to_drop_bi, inplace = True)\n",
    "        data_list.append(data)\n",
    "\n",
    "    rs = random_state\n",
    "    clfs = [] \n",
    "    n_samples = []\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "    y = [np.ones(len(data_list[i])) * (i + 1) for i in range(len(data_list))]\n",
    "    for i in range(len(input_file)): # reading the data\n",
    "        data0 = pd.read_csv(input_file[i])\n",
    "        y[i][data0.is_attack == 0] = 0\n",
    "        n_samples.append(len(y[i])) \n",
    "        x = data_list[i]\n",
    "        x = x.drop(columns='is_attack')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y[i], test_size = test_size, random_state = rs)\n",
    "        x_train_list.append(x_train)\n",
    "        y_train_list.append(y_train)\n",
    "        x_test_list.append(x_test)\n",
    "        y_test_list.append(y_test)\n",
    "\n",
    "    x_train_full = pd.concat(x_train_list, ignore_index=True)\n",
    "    scaler = scale.StandardScaler().fit(x_train_full)\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        x_train_list[i] = scaler.transform(x_train_list[i])\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = random_state)\n",
    "        classifier.fit(x_train_list[i], y_train_list[i])\n",
    "        clfs.append(classifier)\n",
    "\n",
    "    total_n_samples = np.sum(n_samples)\n",
    "    p_nodes =  np.array(n_samples) / total_n_samples\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        x_test_list[i] = scaler.transform(x_test_list[i])\n",
    "\n",
    "    x_test = np.vstack(x_test_list)\n",
    "    y_test = np.hstack(y_test_list)\n",
    "    x_train = np.vstack(x_train_list)\n",
    "    y_train = np.hstack(y_train_list)\n",
    "\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    gms = []\n",
    "    for i in range(len(input_file)):\n",
    "        x = x_train_list[i]\n",
    "        gm = GaussianMixture(n_components = K).fit(x)\n",
    "        gms.append(gm)\n",
    "\n",
    "    prediction = pred(x_test, clfs, p_nodes, gms)\n",
    "\n",
    "    correct = prediction == y_test\n",
    "    accuracy = np.mean(correct)\n",
    "\n",
    "    accs = []\n",
    "    for i in range(len(input_file)+1):\n",
    "        if len(correct[y_test==i]) == 0:\n",
    "            accs.append(0)\n",
    "        else:\n",
    "            accs.append(np.mean(correct[y_test==i]))\n",
    "\n",
    "    recalls = []\n",
    "    for i in range(len(input_file)+1):\n",
    "        if len(correct[prediction==i]) == 0:\n",
    "            recalls.append(0)\n",
    "        else:\n",
    "            recalls.append(np.mean(correct[prediction==i]))\n",
    "\n",
    "    return recalls, accs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% md\n",
    "\n",
    "The process for RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # data = pd.read_csv('openSmile_resampled/overall.csv')\n",
    "\n",
    "    # data = pd.read_csv('openSmile_raw/f.csv')\n",
    "\n",
    "    data = pd.read_csv('openSmile_balanced/f.csv')\n",
    "\n",
    "    # Split the data into features (X) and labels (y)\n",
    "    X = data.drop('y', axis=1)\n",
    "    y = data['y']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    n_estimators_custom = 50\n",
    "    max_depth_custom = 10\n",
    "    min_samples_split_custom = 5\n",
    "    criterion_custom = 'gini'\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators_custom,\n",
    "                                   max_depth=max_depth_custom,\n",
    "                                   min_samples_split=min_samples_split_custom,\n",
    "                                   criterion=criterion_custom,\n",
    "                                   random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    uf1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "    uar = (sensitivity + specificity) / 2\n",
    "\n",
    "    # Calculate UAR and F1\n",
    "    # uar_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    # uf1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Calculate Classification Report\n",
    "    classification_rep = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "    normalized_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RF(epoch, input_file, columns_to_drop_bi, K):\n",
    "\n",
    "   recall , precision = np.ones((epoch,len(input_file)+1))*0 , np.ones((epoch,len(input_file)+1))*0\n",
    "\n",
    "   print('main process:')\n",
    "\n",
    "   for rs in tqdm(range(epoch)):\n",
    "      recalls, accs = Fed_RF_learn(input_file = input_file, columns_to_drop_bi=columns_to_drop_bi, random_state=rs, K=K)\n",
    "      recall[rs,:] = recalls\n",
    "      precision[rs,:] = accs\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Precision mean=',np.mean(precision[:,i]))\n",
    "      print('Precision std=',np.std(precision[:,i]))\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Recall mean of ',i,' =',np.mean(recall[:,i]))\n",
    "      print('Recall std of ',i,' =',np.std(recall[:,i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RF(epoch=1, input_file=input_file, columns_to_drop_bi=columns_to_drop_bi, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Set up the plot\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = '46'\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(normalized_conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=['Normal', 'Abnormal'], yticklabels=['Normal', 'Abnormal'])\n",
    "\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Normalised Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"Unweighted F1-Score (UF1):\", uf1)\n",
    "    print(\"Unweighted Average Recall (UAR):\", uar)\n",
    "    print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for FNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fed_FNN_learn(input_file, columns_to_drop_bi, random_state,  K, test_size = 0.25):\n",
    "    \n",
    "    data_list = []\n",
    "    for i in range(len(input_file)):\n",
    "        data = pd.read_csv(input_file[i])\n",
    "        data.drop(columns = columns_to_drop_bi, inplace = True)\n",
    "        data_list.append(data)\n",
    "\n",
    "    rs = random_state\n",
    "\n",
    "    clfs = []\n",
    "    n_samples = []\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "    y = [np.ones(len(data_list[i])) * (i + 1) for i in range(len(data_list))]\n",
    "    for i in range(len(input_file)): # reading the data\n",
    "        data0 = pd.read_csv(input_file[i])\n",
    "        y[i][data0.is_attack == 0] = 0\n",
    "        n_samples.append(len(y[i])) # the number of this node\n",
    "        x = data_list[i]\n",
    "        x = x.drop(columns='is_abnormal')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y[i], test_size = test_size, random_state = rs)\n",
    "        x_train_list.append(x_train)\n",
    "        y_train_list.append(y_train)\n",
    "        x_test_list.append(x_test)\n",
    "        y_test_list.append(y_test)\n",
    "\n",
    "    x_train_full = pd.concat(x_train_list, ignore_index=True)\n",
    "    scaler = scale.StandardScaler().fit(x_train_full)\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        x_train_list[i] = scaler.transform(x_train_list[i])\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        classifier = LogisticRegression(random_state = random_state+1)\n",
    "        classifier.fit(x_train_list[i], y_train_list[i])\n",
    "        clfs.append(classifier)\n",
    "\n",
    "    total_n_samples = np.sum(n_samples)\n",
    "\n",
    "    p_nodes =  np.array(n_samples) / total_n_samples\n",
    "\n",
    "\n",
    "    for i in range(len(input_file)):\n",
    "        x_test_list[i] = scaler.transform(x_test_list[i])\n",
    "\n",
    "    x_test = np.vstack(x_test_list)\n",
    "    y_test = np.hstack(y_test_list)\n",
    "    x_train = np.vstack(x_train_list)\n",
    "    y_train = np.hstack(y_train_list)\n",
    "\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    gms = []\n",
    "    for i in range(len(input_file)):\n",
    "        x = x_train_list[i]\n",
    "        gm = GaussianMixture(n_components = K).fit(x)  \n",
    "        gms.append(gm)\n",
    "\n",
    "    prediction = pred(x_test, clfs, p_nodes, gms)\n",
    "\n",
    "    correct = prediction == y_test\n",
    "    accuracy = np.mean(correct)\n",
    "\n",
    "    accs = []\n",
    "    for i in range(len(input_file)+1):\n",
    "        if len(correct[y_test==i]) == 0:\n",
    "            accs.append(0)\n",
    "        else:\n",
    "            accs.append(np.mean(correct[y_test==i]))\n",
    "\n",
    "    recalls = []\n",
    "    for i in range(len(input_file)+1):\n",
    "        if len(correct[prediction==i]) == 0:\n",
    "            recalls.append(0)\n",
    "        else:\n",
    "            recalls.append(np.mean(correct[prediction==i]))\n",
    "\n",
    "    return recalls, accs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FNN model\n",
    "\n",
    "class FNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)        \n",
    "    self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    # Load the CSV dataset\n",
    "    # data = pd.read_csv('openSmile_6373/c.csv')\n",
    "\n",
    "    data = pd.read_csv('openSmile_resampled/overall.csv')\n",
    "\n",
    "    # data = pd.read_csv('openSmile_raw/overall.csv')\n",
    "\n",
    "    # Split the data into features (X) and labels (y)\n",
    "    X = data.iloc[:, 2:].values\n",
    "    y = data.iloc[:, 1].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "    # Create DataLoader for training\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize the model and optimizer\n",
    "    input_size = X_train.shape[1]\n",
    "    model = FNNModel(input_size)\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    with torch.no_grad():\n",
    "        y_pred_probs = model(X_test_tensor)\n",
    "        y_pred = (y_pred_probs >= 0.5).squeeze().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    uf1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "    uar = (sensitivity + specificity) / 2\n",
    "\n",
    "    classification_rep = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "    normalized_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main process:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b4175f10e7436086669770b3176186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision mean= 0.9999609801779303\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.999712395743457\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.9991109530583214\n",
      "Precision std= 0.0\n",
      "Precision mean= 1.0\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.9721456150027579\n",
      "Precision std= 0.0\n",
      "Recall mean of  0  = 0.9958420766301391\n",
      "Recall std of  0  = 0.0\n",
      "Recall mean of  1  = 1.0\n",
      "Recall std of  1  = 0.0\n",
      "Recall mean of  2  = 0.9998220640569395\n",
      "Recall std of  2  = 0.0\n",
      "Recall mean of  3  = 1.0\n",
      "Recall std of  3  = 0.0\n",
      "Recall mean of  4  = 1.0\n",
      "Recall std of  4  = 0.0\n"
     ]
    }
   ],
   "source": [
    "def test_FNN(epoch, input_file, columns_to_drop_bi, K):\n",
    "\n",
    "   recall , precision = np.ones((epoch,len(input_file)+1))*0 , np.ones((epoch,len(input_file)+1))*0\n",
    "\n",
    "   print('main process:')\n",
    "\n",
    "   for rs in tqdm(range(epoch)):\n",
    "      recalls, accs = Fed_FNN_learn(input_file = input_file, columns_to_drop_bi=columns_to_drop_bi, random_state=rs, K=K)\n",
    "      recall[rs,:] = recalls\n",
    "      precision[rs,:] = accs\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Precision mean=',np.mean(precision[:,i]))\n",
    "      print('Precision std=',np.std(precision[:,i]))\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Recall mean of ',i,' =',np.mean(recall[:,i]))\n",
    "      print('Recall std of ',i,' =',np.std(recall[:,i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_FNN(epoch=1, input_file=input_file, columns_to_drop_bi=columns_to_drop_bi, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"Unweighted F1-Score (UF1):\", uf1)\n",
    "    print(\"Unweighted Average Recall (UAR):\", uar)\n",
    "\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = '46'\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(normalized_conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=['Normal', 'Abnormal'], yticklabels=['Normal', 'Abnormal'])\n",
    "\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Normalised Confusion Matrix')\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary = CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, labels_data, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.labels_data = labels_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_name = os.path.join(self.image_folder, f'e{str(idx+1).zfill(5)}.png')\n",
    "        img_name = os.path.join(self.image_folder, self.labels_data.iloc[idx, 0])\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.labels_data.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# raw data\n",
    "# image_folder = 'image_cwt_raw/overall'\n",
    "# labels_file = 'image_cwt_raw/overall_labels.csv'\n",
    "\n",
    "image_folder = 'CWT_data_resampled/overall'\n",
    "labels_file = 'CWT_data_resampled/overall_labels.csv'\n",
    "\n",
    "# balanced data\n",
    "# image_folder = 'CWT_data_resampled/training-e1'\n",
    "# labels_file = 'CWT_data_resampled/training-e/e_labels.csv'\n",
    "\n",
    "# Load and split the data\n",
    "labels_data = pd.read_csv(labels_file)\n",
    "train_data, test_data = train_test_split(labels_data, test_size=0.3, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(image_folder, train_data, transform=transform)\n",
    "test_dataset = CustomDataset(image_folder, test_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the CNN model and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = []\n",
    "    y_true = []\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X)\n",
    "        y_pred_probs.extend(outputs)\n",
    "        y_true.extend(batch_y)\n",
    "\n",
    "y_pred_probs = torch.cat(y_pred_probs)\n",
    "y_pred = (y_pred_probs >= 0.5).float()\n",
    "y_true = torch.tensor(y_true)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "uf1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "uar = (sensitivity + specificity) / 2\n",
    "\n",
    "# Calculate the normalized confusion matrix\n",
    "normalized_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Print metrics\n",
    "classification_rep = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "normalized_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CNN(epoch, input_file, columns_to_drop_bi, K):\n",
    "\n",
    "   recall , precision = np.ones((epoch,len(input_file)+1))*0 , np.ones((epoch,len(input_file)+1))*0\n",
    "\n",
    "   print('main process:')\n",
    "\n",
    "   for rs in tqdm(range(epoch)):\n",
    "      recalls, accs = Fed_CNN_learn(input_file = input_file, columns_to_drop_bi=columns_to_drop_bi, random_state=rs, K=K)\n",
    "      recall[rs,:] = recalls\n",
    "      precision[rs,:] = accs\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Precision mean=',np.mean(precision[:,i]))\n",
    "      print('Precision std=',np.std(precision[:,i]))\n",
    "\n",
    "   for i in range(len(input_file)+1):\n",
    "      print('Recall mean of ',i,' =',np.mean(recall[:,i]))\n",
    "      print('Recall std of ',i,' =',np.std(recall[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main process:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66072e8c07f0471d8cf4d9b7a6911749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irohayachiyo/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision mean= 0.9980099890744498\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.999712395743457\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.9987553342816501\n",
      "Precision std= 0.0\n",
      "Precision mean= 1.0\n",
      "Precision std= 0.0\n",
      "Precision mean= 0.9721456150027579\n",
      "Precision std= 0.0\n",
      "Recall mean of  0  = 0.9957564431986295\n",
      "Recall std of  0  = 0.0\n",
      "Recall mean of  1  = 1.0\n",
      "Recall std of  1  = 0.0\n",
      "Recall mean of  2  = 0.9910021171489062\n",
      "Recall std of  2  = 0.0\n",
      "Recall mean of  3  = 1.0\n",
      "Recall std of  3  = 0.0\n",
      "Recall mean of  4  = 1.0\n",
      "Recall std of  4  = 0.0\n"
     ]
    }
   ],
   "source": [
    "test_CNN(epoch=1, input_file=input_file, columns_to_drop_bi=columns_to_drop_bi, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Unweighted F1-Score (UF1):\", uf1)\n",
    "print(\"Unweighted Average Recall (UAR):\", uar)\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = '46'\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(normalized_conf_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=['Normal', 'Abnormal'], yticklabels=['Normal', 'Abnormal'])\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Normalised Confusion Matrix')\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad6a9ebe595c8604775664ccb6b4edb43e0871577ed89c469f16f6efb723bbd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
